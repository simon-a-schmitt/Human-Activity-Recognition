{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65801d55-8613-4da7-9984-709822681ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: edge-ml in /opt/conda/lib/python3.12/site-packages (0.4.0)\n",
      "Requirement already satisfied: tsflex in /opt/conda/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.12/site-packages (6.2.0)\n",
      "Requirement already satisfied: tsfresh in /opt/conda/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: timeout_decorator in /opt/conda/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from optuna) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.8 in /opt/conda/lib/python3.12/site-packages (from tsflex) (0.3.9)\n",
      "Requirement already satisfied: multiprocess<0.71.0,>=0.70.16 in /opt/conda/lib/python3.12/site-packages (from tsflex) (0.70.17)\n",
      "Requirement already satisfied: pandas>=2 in /opt/conda/lib/python3.12/site-packages (from tsflex) (2.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/conda/lib/python3.12/site-packages (from plotly) (1.34.1)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.12/site-packages (from tsfresh) (2.32.3)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/conda/lib/python3.12/site-packages (from tsfresh) (0.14.4)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /opt/conda/lib/python3.12/site-packages (from tsfresh) (1.0.1)\n",
      "Requirement already satisfied: pywavelets in /opt/conda/lib/python3.12/site-packages (from tsfresh) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from tsfresh) (1.6.1)\n",
      "Requirement already satisfied: stumpy>=1.7.2 in /opt/conda/lib/python3.12/site-packages (from tsfresh) (1.13.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.12/site-packages (from tsfresh) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from tsfresh) (1.15.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=2->tsflex) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=2->tsflex) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=2->tsflex) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.9.1->tsfresh) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.9.1->tsfresh) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.9.1->tsfresh) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.9.1->tsfresh) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn>=0.22.0->tsfresh) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn>=0.22.0->tsfresh) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: numba>=0.57.1 in /opt/conda/lib/python3.12/site-packages (from stumpy>=1.7.2->tsfresh) (0.61.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.12/site-packages (from numba>=0.57.1->stumpy>=1.7.2->tsfresh) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2->tsflex) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna edge-ml tsflex plotly tsfresh torch timeout_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c3d1fa-a06f-4b9e-8ab5-f68dd9bea42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "project=pickle.load(open(\"data_snapshot/project_css25.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcebbe4-58a2-47b5-8e6d-cdc5038ccc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor=\"deviceorientation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5e171b-e580-4c8a-9737-6fad7959191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([d.data.iloc[40:-40].dropna().assign(**d.metaData) for d  in project.datasets if (d.name == sensor and d.data.shape[0]>0) and d.timeSeries[0].end-d.timeSeries[0].start>10000] )\n",
    "df.set_index([\"participantId\",\"time\"], inplace=True)\n",
    "df=df[df.activity!=\"testing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49261ab4-9a05-48c3-a7aa-13fe93a031ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha', 'beta', 'gamma']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_cols=[col for col in df.columns if col not in [\"activity\",\"mobile\",\"browser\"] ]\n",
    "ts_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9d9f55-0e36-4b7d-b942-bfed1a4f7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsflex.features import FeatureCollection, FuncWrapper, MultipleFeatureDescriptors\n",
    "from tsflex.processing import SeriesProcessor\n",
    "from tsflex.features.integrations import tsfresh_settings_wrapper\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "\n",
    "# Common statistical + signal features approximating TSFRESH minimal set\n",
    "tsfresh_minimal_funcs =   [\n",
    "        FuncWrapper(np.sum, output_names=\"sum\"),\n",
    "        FuncWrapper(np.median, output_names=\"median\"),\n",
    "        FuncWrapper(np.mean, output_names=\"mean\"),\n",
    "        FuncWrapper(lambda x: len(x), output_names=\"length\"),\n",
    "        FuncWrapper(np.std, output_names=\"std_dev\"),\n",
    "        FuncWrapper(np.var, output_names=\"var\"),\n",
    "        FuncWrapper(lambda x: np.sqrt(np.mean(np.square(x))), output_names=\"root_mean_square\"),\n",
    "        FuncWrapper(lambda x: np.max(x) if len(x) > 0 else np.nan, output_names=\"max\"),\n",
    "        FuncWrapper(lambda x: np.max(np.abs(x)) if len(x) > 0 else np.nan, output_names=\"abs_max\"),\n",
    "        FuncWrapper(lambda x: np.min(x) if len(x) > 0 else np.nan, output_names=\"min\"),\n",
    "    ]\n",
    "#tsfresh_minimal_funcs=tsfresh_settings_wrapper(MinimalFCParameters())\n",
    "\n",
    "\n",
    "fc = FeatureCollection( feature_descriptors = [ MultipleFeatureDescriptors(  \n",
    "        series_names=ts_cols , \n",
    "        functions=tsfresh_minimal_funcs,\n",
    "        windows=[\"1s\"],\n",
    "        strides=[\"1000ms\"]\n",
    "        )\n",
    "        ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73bd7276-bc99-45a3-9052-bb76a1d1849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f442dfed3d480d9382f878b305df44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing groups:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha__sum__w=1s</th>\n",
       "      <th>alpha__median__w=1s</th>\n",
       "      <th>alpha__mean__w=1s</th>\n",
       "      <th>alpha__length__w=1s</th>\n",
       "      <th>alpha__std_dev__w=1s</th>\n",
       "      <th>alpha__var__w=1s</th>\n",
       "      <th>alpha__root_mean_square__w=1s</th>\n",
       "      <th>alpha__max__w=1s</th>\n",
       "      <th>alpha__abs_max__w=1s</th>\n",
       "      <th>alpha__min__w=1s</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma__median__w=1s</th>\n",
       "      <th>gamma__mean__w=1s</th>\n",
       "      <th>gamma__length__w=1s</th>\n",
       "      <th>gamma__std_dev__w=1s</th>\n",
       "      <th>gamma__var__w=1s</th>\n",
       "      <th>gamma__root_mean_square__w=1s</th>\n",
       "      <th>gamma__max__w=1s</th>\n",
       "      <th>gamma__abs_max__w=1s</th>\n",
       "      <th>gamma__min__w=1s</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantId</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10d83</th>\n",
       "      <th>2025-06-03 12:01:24.781</th>\n",
       "      <td>2515.500000</td>\n",
       "      <td>83.850006</td>\n",
       "      <td>83.849998</td>\n",
       "      <td>30</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>83.850075</td>\n",
       "      <td>84.099998</td>\n",
       "      <td>84.099998</td>\n",
       "      <td>83.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.093333</td>\n",
       "      <td>30</td>\n",
       "      <td>0.169181</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>7.095351</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>6.70</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:25.781</th>\n",
       "      <td>3036.300049</td>\n",
       "      <td>84.099998</td>\n",
       "      <td>84.341667</td>\n",
       "      <td>36</td>\n",
       "      <td>0.519816</td>\n",
       "      <td>0.270209</td>\n",
       "      <td>84.343269</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.733334</td>\n",
       "      <td>36</td>\n",
       "      <td>0.568135</td>\n",
       "      <td>0.322778</td>\n",
       "      <td>6.757259</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:26.781</th>\n",
       "      <td>2552.300049</td>\n",
       "      <td>85.099998</td>\n",
       "      <td>85.076668</td>\n",
       "      <td>30</td>\n",
       "      <td>0.192671</td>\n",
       "      <td>0.037122</td>\n",
       "      <td>85.076889</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450</td>\n",
       "      <td>6.340001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.416013</td>\n",
       "      <td>0.173067</td>\n",
       "      <td>6.353634</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5.40</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:27.781</th>\n",
       "      <td>1947.899902</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>84.691299</td>\n",
       "      <td>23</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>84.691399</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.078261</td>\n",
       "      <td>23</td>\n",
       "      <td>0.131733</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>7.079486</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:28.781</th>\n",
       "      <td>1778.200195</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>84.676201</td>\n",
       "      <td>21</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>84.676262</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.133334</td>\n",
       "      <td>21</td>\n",
       "      <td>0.083571</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>7.133823</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1f683</th>\n",
       "      <th>2025-06-23 19:10:25.060</th>\n",
       "      <td>973.820007</td>\n",
       "      <td>16.240000</td>\n",
       "      <td>16.230333</td>\n",
       "      <td>60</td>\n",
       "      <td>0.036922</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>16.230375</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.940</td>\n",
       "      <td>-3.894166</td>\n",
       "      <td>60</td>\n",
       "      <td>0.176279</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>3.898154</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>4.06</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:26.060</th>\n",
       "      <td>972.840027</td>\n",
       "      <td>16.270000</td>\n",
       "      <td>16.214001</td>\n",
       "      <td>60</td>\n",
       "      <td>0.160958</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>16.214800</td>\n",
       "      <td>16.379999</td>\n",
       "      <td>16.379999</td>\n",
       "      <td>15.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.655</td>\n",
       "      <td>-3.572834</td>\n",
       "      <td>60</td>\n",
       "      <td>0.170138</td>\n",
       "      <td>0.028947</td>\n",
       "      <td>3.576882</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:27.060</th>\n",
       "      <td>977.849976</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.297499</td>\n",
       "      <td>60</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>16.297590</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.830</td>\n",
       "      <td>-3.801833</td>\n",
       "      <td>60</td>\n",
       "      <td>0.099155</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>3.803126</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:28.060</th>\n",
       "      <td>979.290100</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.321501</td>\n",
       "      <td>60</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.016239</td>\n",
       "      <td>16.321999</td>\n",
       "      <td>16.459999</td>\n",
       "      <td>16.459999</td>\n",
       "      <td>15.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.765</td>\n",
       "      <td>-4.044000</td>\n",
       "      <td>60</td>\n",
       "      <td>0.432201</td>\n",
       "      <td>0.186797</td>\n",
       "      <td>4.067030</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>4.97</td>\n",
       "      <td>-4.97</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:29.060</th>\n",
       "      <td>834.509949</td>\n",
       "      <td>12.525000</td>\n",
       "      <td>13.908499</td>\n",
       "      <td>60</td>\n",
       "      <td>2.439942</td>\n",
       "      <td>5.953319</td>\n",
       "      <td>14.120895</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>11.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.145</td>\n",
       "      <td>-13.838166</td>\n",
       "      <td>60</td>\n",
       "      <td>5.448740</td>\n",
       "      <td>29.688772</td>\n",
       "      <td>14.872244</td>\n",
       "      <td>-5.06</td>\n",
       "      <td>20.18</td>\n",
       "      <td>-20.18</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       alpha__sum__w=1s  alpha__median__w=1s  \\\n",
       "participantId time                                                             \n",
       "10d83         2025-06-03 12:01:24.781       2515.500000            83.850006   \n",
       "              2025-06-03 12:01:25.781       3036.300049            84.099998   \n",
       "              2025-06-03 12:01:26.781       2552.300049            85.099998   \n",
       "              2025-06-03 12:01:27.781       1947.899902            84.699997   \n",
       "              2025-06-03 12:01:28.781       1778.200195            84.699997   \n",
       "...                                                 ...                  ...   \n",
       "1f683         2025-06-23 19:10:25.060        973.820007            16.240000   \n",
       "              2025-06-23 19:10:26.060        972.840027            16.270000   \n",
       "              2025-06-23 19:10:27.060        977.849976            16.309999   \n",
       "              2025-06-23 19:10:28.060        979.290100            16.370001   \n",
       "              2025-06-23 19:10:29.060        834.509949            12.525000   \n",
       "\n",
       "                                       alpha__mean__w=1s  alpha__length__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781          83.849998                   30   \n",
       "              2025-06-03 12:01:25.781          84.341667                   36   \n",
       "              2025-06-03 12:01:26.781          85.076668                   30   \n",
       "              2025-06-03 12:01:27.781          84.691299                   23   \n",
       "              2025-06-03 12:01:28.781          84.676201                   21   \n",
       "...                                                  ...                  ...   \n",
       "1f683         2025-06-23 19:10:25.060          16.230333                   60   \n",
       "              2025-06-23 19:10:26.060          16.214001                   60   \n",
       "              2025-06-23 19:10:27.060          16.297499                   60   \n",
       "              2025-06-23 19:10:28.060          16.321501                   60   \n",
       "              2025-06-23 19:10:29.060          13.908499                   60   \n",
       "\n",
       "                                       alpha__std_dev__w=1s  alpha__var__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781              0.117615          0.013833   \n",
       "              2025-06-03 12:01:25.781              0.519816          0.270209   \n",
       "              2025-06-03 12:01:26.781              0.192671          0.037122   \n",
       "              2025-06-03 12:01:27.781              0.128243          0.016446   \n",
       "              2025-06-03 12:01:28.781              0.106481          0.011338   \n",
       "...                                                     ...               ...   \n",
       "1f683         2025-06-23 19:10:25.060              0.036922          0.001363   \n",
       "              2025-06-23 19:10:26.060              0.160958          0.025907   \n",
       "              2025-06-23 19:10:27.060              0.054517          0.002972   \n",
       "              2025-06-23 19:10:28.060              0.127434          0.016239   \n",
       "              2025-06-23 19:10:29.060              2.439942          5.953319   \n",
       "\n",
       "                                       alpha__root_mean_square__w=1s  \\\n",
       "participantId time                                                     \n",
       "10d83         2025-06-03 12:01:24.781                      83.850075   \n",
       "              2025-06-03 12:01:25.781                      84.343269   \n",
       "              2025-06-03 12:01:26.781                      85.076889   \n",
       "              2025-06-03 12:01:27.781                      84.691399   \n",
       "              2025-06-03 12:01:28.781                      84.676262   \n",
       "...                                                              ...   \n",
       "1f683         2025-06-23 19:10:25.060                      16.230375   \n",
       "              2025-06-23 19:10:26.060                      16.214800   \n",
       "              2025-06-23 19:10:27.060                      16.297590   \n",
       "              2025-06-23 19:10:28.060                      16.321999   \n",
       "              2025-06-23 19:10:29.060                      14.120895   \n",
       "\n",
       "                                       alpha__max__w=1s  alpha__abs_max__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781         84.099998             84.099998   \n",
       "              2025-06-03 12:01:25.781         85.400002             85.400002   \n",
       "              2025-06-03 12:01:26.781         85.500000             85.500000   \n",
       "              2025-06-03 12:01:27.781         85.000000             85.000000   \n",
       "              2025-06-03 12:01:28.781         84.800003             84.800003   \n",
       "...                                                 ...                   ...   \n",
       "1f683         2025-06-23 19:10:25.060         16.309999             16.309999   \n",
       "              2025-06-23 19:10:26.060         16.379999             16.379999   \n",
       "              2025-06-23 19:10:27.060         16.370001             16.370001   \n",
       "              2025-06-23 19:10:28.060         16.459999             16.459999   \n",
       "              2025-06-23 19:10:29.060         17.719999             17.719999   \n",
       "\n",
       "                                       alpha__min__w=1s  ...  \\\n",
       "participantId time                                       ...   \n",
       "10d83         2025-06-03 12:01:24.781         83.599998  ...   \n",
       "              2025-06-03 12:01:25.781         83.800003  ...   \n",
       "              2025-06-03 12:01:26.781         84.699997  ...   \n",
       "              2025-06-03 12:01:27.781         84.500000  ...   \n",
       "              2025-06-03 12:01:28.781         84.500000  ...   \n",
       "...                                                 ...  ...   \n",
       "1f683         2025-06-23 19:10:25.060         16.160000  ...   \n",
       "              2025-06-23 19:10:26.060         15.850000  ...   \n",
       "              2025-06-23 19:10:27.060         16.170000  ...   \n",
       "              2025-06-23 19:10:28.060         15.940000  ...   \n",
       "              2025-06-23 19:10:29.060         11.410000  ...   \n",
       "\n",
       "                                       gamma__median__w=1s  gamma__mean__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781                7.100           7.093333   \n",
       "              2025-06-03 12:01:25.781                7.000           6.733334   \n",
       "              2025-06-03 12:01:26.781                6.450           6.340001   \n",
       "              2025-06-03 12:01:27.781                7.100           7.078261   \n",
       "              2025-06-03 12:01:28.781                7.100           7.133334   \n",
       "...                                                    ...                ...   \n",
       "1f683         2025-06-23 19:10:25.060               -3.940          -3.894166   \n",
       "              2025-06-23 19:10:26.060               -3.655          -3.572834   \n",
       "              2025-06-23 19:10:27.060               -3.830          -3.801833   \n",
       "              2025-06-23 19:10:28.060               -3.765          -4.044000   \n",
       "              2025-06-23 19:10:29.060              -15.145         -13.838166   \n",
       "\n",
       "                                       gamma__length__w=1s  \\\n",
       "participantId time                                           \n",
       "10d83         2025-06-03 12:01:24.781                   30   \n",
       "              2025-06-03 12:01:25.781                   36   \n",
       "              2025-06-03 12:01:26.781                   30   \n",
       "              2025-06-03 12:01:27.781                   23   \n",
       "              2025-06-03 12:01:28.781                   21   \n",
       "...                                                    ...   \n",
       "1f683         2025-06-23 19:10:25.060                   60   \n",
       "              2025-06-23 19:10:26.060                   60   \n",
       "              2025-06-23 19:10:27.060                   60   \n",
       "              2025-06-23 19:10:28.060                   60   \n",
       "              2025-06-23 19:10:29.060                   60   \n",
       "\n",
       "                                       gamma__std_dev__w=1s  gamma__var__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781              0.169181          0.028622   \n",
       "              2025-06-03 12:01:25.781              0.568135          0.322778   \n",
       "              2025-06-03 12:01:26.781              0.416013          0.173067   \n",
       "              2025-06-03 12:01:27.781              0.131733          0.017353   \n",
       "              2025-06-03 12:01:28.781              0.083571          0.006984   \n",
       "...                                                     ...               ...   \n",
       "1f683         2025-06-23 19:10:25.060              0.176279          0.031074   \n",
       "              2025-06-23 19:10:26.060              0.170138          0.028947   \n",
       "              2025-06-23 19:10:27.060              0.099155          0.009832   \n",
       "              2025-06-23 19:10:28.060              0.432201          0.186797   \n",
       "              2025-06-23 19:10:29.060              5.448740         29.688772   \n",
       "\n",
       "                                       gamma__root_mean_square__w=1s  \\\n",
       "participantId time                                                     \n",
       "10d83         2025-06-03 12:01:24.781                       7.095351   \n",
       "              2025-06-03 12:01:25.781                       6.757259   \n",
       "              2025-06-03 12:01:26.781                       6.353634   \n",
       "              2025-06-03 12:01:27.781                       7.079486   \n",
       "              2025-06-03 12:01:28.781                       7.133823   \n",
       "...                                                              ...   \n",
       "1f683         2025-06-23 19:10:25.060                       3.898154   \n",
       "              2025-06-23 19:10:26.060                       3.576882   \n",
       "              2025-06-23 19:10:27.060                       3.803126   \n",
       "              2025-06-23 19:10:28.060                       4.067030   \n",
       "              2025-06-23 19:10:29.060                      14.872244   \n",
       "\n",
       "                                       gamma__max__w=1s  gamma__abs_max__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781              7.40                  7.40   \n",
       "              2025-06-03 12:01:25.781              7.30                  7.30   \n",
       "              2025-06-03 12:01:26.781              6.90                  6.90   \n",
       "              2025-06-03 12:01:27.781              7.30                  7.30   \n",
       "              2025-06-03 12:01:28.781              7.30                  7.30   \n",
       "...                                                 ...                   ...   \n",
       "1f683         2025-06-23 19:10:25.060             -3.44                  4.06   \n",
       "              2025-06-23 19:10:26.060             -3.25                  3.76   \n",
       "              2025-06-23 19:10:27.060             -3.58                  3.93   \n",
       "              2025-06-23 19:10:28.060             -3.69                  4.97   \n",
       "              2025-06-23 19:10:29.060             -5.06                 20.18   \n",
       "\n",
       "                                       gamma__min__w=1s  activity  \n",
       "participantId time                                                 \n",
       "10d83         2025-06-03 12:01:24.781              6.70   sitting  \n",
       "              2025-06-03 12:01:25.781              5.50   sitting  \n",
       "              2025-06-03 12:01:26.781              5.40   sitting  \n",
       "              2025-06-03 12:01:27.781              6.80   sitting  \n",
       "              2025-06-03 12:01:28.781              7.00   sitting  \n",
       "...                                                 ...       ...  \n",
       "1f683         2025-06-23 19:10:25.060             -4.06   sitting  \n",
       "              2025-06-23 19:10:26.060             -3.76   sitting  \n",
       "              2025-06-23 19:10:27.060             -3.93   sitting  \n",
       "              2025-06-23 19:10:28.060             -4.97   sitting  \n",
       "              2025-06-23 19:10:29.060            -20.18   sitting  \n",
       "\n",
       "[945 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env PYTHONWARNINGS=ignore\n",
    "\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare the groups\n",
    "grouped = df.reset_index().set_index(\"time\").groupby([\"participantId\", \"activity\"])\n",
    "\n",
    "# Optional: Convert to a list to avoid multiple iterations over the generator\n",
    "grouped_items = list(grouped)\n",
    "\n",
    "# Define your processing function\n",
    "def process_group(pid, group):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    feats=pd.concat(fc.calculate(group, n_jobs=1),axis=1)\n",
    "    #display(feats)\n",
    "    feats[\"participantId\"]=pid[0]\n",
    "    feats[\"activity\"] = pid[1]\n",
    "    return feats.dropna().reset_index().set_index([\"participantId\",\"time\"])\n",
    "\n",
    "# Wrap with tqdm for progress\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_group)(pid, group)\n",
    "    for pid, group in tqdm(grouped_items, desc=\"Processing groups\")\n",
    ")\n",
    "\n",
    "\n",
    "df1=pd.concat(results, axis=0)\n",
    " #   display(all_feats)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568d6f84-36c9-4833-83fb-ff171174e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FuncWrapper(sum, ['sum'], {}),\n",
       " FuncWrapper(median, ['median'], {}),\n",
       " FuncWrapper(mean, ['mean'], {}),\n",
       " FuncWrapper(<lambda>, ['length'], {}),\n",
       " FuncWrapper(std, ['std_dev'], {}),\n",
       " FuncWrapper(var, ['var'], {}),\n",
       " FuncWrapper(<lambda>, ['root_mean_square'], {}),\n",
       " FuncWrapper(<lambda>, ['max'], {}),\n",
       " FuncWrapper(<lambda>, ['abs_max'], {}),\n",
       " FuncWrapper(<lambda>, ['min'], {})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfresh_minimal_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa67fb41-af85-40a4-ab0e-2f316ff27bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha__sum__w=1s</th>\n",
       "      <th>alpha__median__w=1s</th>\n",
       "      <th>alpha__mean__w=1s</th>\n",
       "      <th>alpha__length__w=1s</th>\n",
       "      <th>alpha__std_dev__w=1s</th>\n",
       "      <th>alpha__var__w=1s</th>\n",
       "      <th>alpha__root_mean_square__w=1s</th>\n",
       "      <th>alpha__max__w=1s</th>\n",
       "      <th>alpha__abs_max__w=1s</th>\n",
       "      <th>alpha__min__w=1s</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma__median__w=1s</th>\n",
       "      <th>gamma__mean__w=1s</th>\n",
       "      <th>gamma__length__w=1s</th>\n",
       "      <th>gamma__std_dev__w=1s</th>\n",
       "      <th>gamma__var__w=1s</th>\n",
       "      <th>gamma__root_mean_square__w=1s</th>\n",
       "      <th>gamma__max__w=1s</th>\n",
       "      <th>gamma__abs_max__w=1s</th>\n",
       "      <th>gamma__min__w=1s</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantId</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10d83</th>\n",
       "      <th>2025-06-03 12:01:24.781</th>\n",
       "      <td>2515.500000</td>\n",
       "      <td>83.850006</td>\n",
       "      <td>83.849998</td>\n",
       "      <td>30</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>83.850075</td>\n",
       "      <td>84.099998</td>\n",
       "      <td>84.099998</td>\n",
       "      <td>83.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.093333</td>\n",
       "      <td>30</td>\n",
       "      <td>0.169181</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>7.095351</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>6.70</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:25.781</th>\n",
       "      <td>3036.300049</td>\n",
       "      <td>84.099998</td>\n",
       "      <td>84.341667</td>\n",
       "      <td>36</td>\n",
       "      <td>0.519816</td>\n",
       "      <td>0.270209</td>\n",
       "      <td>84.343269</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.733334</td>\n",
       "      <td>36</td>\n",
       "      <td>0.568135</td>\n",
       "      <td>0.322778</td>\n",
       "      <td>6.757259</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:26.781</th>\n",
       "      <td>2552.300049</td>\n",
       "      <td>85.099998</td>\n",
       "      <td>85.076668</td>\n",
       "      <td>30</td>\n",
       "      <td>0.192671</td>\n",
       "      <td>0.037122</td>\n",
       "      <td>85.076889</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450</td>\n",
       "      <td>6.340001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.416013</td>\n",
       "      <td>0.173067</td>\n",
       "      <td>6.353634</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5.40</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:27.781</th>\n",
       "      <td>1947.899902</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>84.691299</td>\n",
       "      <td>23</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>84.691399</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.078261</td>\n",
       "      <td>23</td>\n",
       "      <td>0.131733</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>7.079486</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 12:01:28.781</th>\n",
       "      <td>1778.200195</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>84.676201</td>\n",
       "      <td>21</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>84.676262</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.133334</td>\n",
       "      <td>21</td>\n",
       "      <td>0.083571</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>7.133823</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1f683</th>\n",
       "      <th>2025-06-23 19:10:25.060</th>\n",
       "      <td>973.820007</td>\n",
       "      <td>16.240000</td>\n",
       "      <td>16.230333</td>\n",
       "      <td>60</td>\n",
       "      <td>0.036922</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>16.230375</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.940</td>\n",
       "      <td>-3.894166</td>\n",
       "      <td>60</td>\n",
       "      <td>0.176279</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>3.898154</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>4.06</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:26.060</th>\n",
       "      <td>972.840027</td>\n",
       "      <td>16.270000</td>\n",
       "      <td>16.214001</td>\n",
       "      <td>60</td>\n",
       "      <td>0.160958</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>16.214800</td>\n",
       "      <td>16.379999</td>\n",
       "      <td>16.379999</td>\n",
       "      <td>15.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.655</td>\n",
       "      <td>-3.572834</td>\n",
       "      <td>60</td>\n",
       "      <td>0.170138</td>\n",
       "      <td>0.028947</td>\n",
       "      <td>3.576882</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:27.060</th>\n",
       "      <td>977.849976</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.297499</td>\n",
       "      <td>60</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>16.297590</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.830</td>\n",
       "      <td>-3.801833</td>\n",
       "      <td>60</td>\n",
       "      <td>0.099155</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>3.803126</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:28.060</th>\n",
       "      <td>979.290100</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.321501</td>\n",
       "      <td>60</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.016239</td>\n",
       "      <td>16.321999</td>\n",
       "      <td>16.459999</td>\n",
       "      <td>16.459999</td>\n",
       "      <td>15.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.765</td>\n",
       "      <td>-4.044000</td>\n",
       "      <td>60</td>\n",
       "      <td>0.432201</td>\n",
       "      <td>0.186797</td>\n",
       "      <td>4.067030</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>4.97</td>\n",
       "      <td>-4.97</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23 19:10:29.060</th>\n",
       "      <td>834.509949</td>\n",
       "      <td>12.525000</td>\n",
       "      <td>13.908499</td>\n",
       "      <td>60</td>\n",
       "      <td>2.439942</td>\n",
       "      <td>5.953319</td>\n",
       "      <td>14.120895</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>11.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.145</td>\n",
       "      <td>-13.838166</td>\n",
       "      <td>60</td>\n",
       "      <td>5.448740</td>\n",
       "      <td>29.688772</td>\n",
       "      <td>14.872244</td>\n",
       "      <td>-5.06</td>\n",
       "      <td>20.18</td>\n",
       "      <td>-20.18</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       alpha__sum__w=1s  alpha__median__w=1s  \\\n",
       "participantId time                                                             \n",
       "10d83         2025-06-03 12:01:24.781       2515.500000            83.850006   \n",
       "              2025-06-03 12:01:25.781       3036.300049            84.099998   \n",
       "              2025-06-03 12:01:26.781       2552.300049            85.099998   \n",
       "              2025-06-03 12:01:27.781       1947.899902            84.699997   \n",
       "              2025-06-03 12:01:28.781       1778.200195            84.699997   \n",
       "...                                                 ...                  ...   \n",
       "1f683         2025-06-23 19:10:25.060        973.820007            16.240000   \n",
       "              2025-06-23 19:10:26.060        972.840027            16.270000   \n",
       "              2025-06-23 19:10:27.060        977.849976            16.309999   \n",
       "              2025-06-23 19:10:28.060        979.290100            16.370001   \n",
       "              2025-06-23 19:10:29.060        834.509949            12.525000   \n",
       "\n",
       "                                       alpha__mean__w=1s  alpha__length__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781          83.849998                   30   \n",
       "              2025-06-03 12:01:25.781          84.341667                   36   \n",
       "              2025-06-03 12:01:26.781          85.076668                   30   \n",
       "              2025-06-03 12:01:27.781          84.691299                   23   \n",
       "              2025-06-03 12:01:28.781          84.676201                   21   \n",
       "...                                                  ...                  ...   \n",
       "1f683         2025-06-23 19:10:25.060          16.230333                   60   \n",
       "              2025-06-23 19:10:26.060          16.214001                   60   \n",
       "              2025-06-23 19:10:27.060          16.297499                   60   \n",
       "              2025-06-23 19:10:28.060          16.321501                   60   \n",
       "              2025-06-23 19:10:29.060          13.908499                   60   \n",
       "\n",
       "                                       alpha__std_dev__w=1s  alpha__var__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781              0.117615          0.013833   \n",
       "              2025-06-03 12:01:25.781              0.519816          0.270209   \n",
       "              2025-06-03 12:01:26.781              0.192671          0.037122   \n",
       "              2025-06-03 12:01:27.781              0.128243          0.016446   \n",
       "              2025-06-03 12:01:28.781              0.106481          0.011338   \n",
       "...                                                     ...               ...   \n",
       "1f683         2025-06-23 19:10:25.060              0.036922          0.001363   \n",
       "              2025-06-23 19:10:26.060              0.160958          0.025907   \n",
       "              2025-06-23 19:10:27.060              0.054517          0.002972   \n",
       "              2025-06-23 19:10:28.060              0.127434          0.016239   \n",
       "              2025-06-23 19:10:29.060              2.439942          5.953319   \n",
       "\n",
       "                                       alpha__root_mean_square__w=1s  \\\n",
       "participantId time                                                     \n",
       "10d83         2025-06-03 12:01:24.781                      83.850075   \n",
       "              2025-06-03 12:01:25.781                      84.343269   \n",
       "              2025-06-03 12:01:26.781                      85.076889   \n",
       "              2025-06-03 12:01:27.781                      84.691399   \n",
       "              2025-06-03 12:01:28.781                      84.676262   \n",
       "...                                                              ...   \n",
       "1f683         2025-06-23 19:10:25.060                      16.230375   \n",
       "              2025-06-23 19:10:26.060                      16.214800   \n",
       "              2025-06-23 19:10:27.060                      16.297590   \n",
       "              2025-06-23 19:10:28.060                      16.321999   \n",
       "              2025-06-23 19:10:29.060                      14.120895   \n",
       "\n",
       "                                       alpha__max__w=1s  alpha__abs_max__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781         84.099998             84.099998   \n",
       "              2025-06-03 12:01:25.781         85.400002             85.400002   \n",
       "              2025-06-03 12:01:26.781         85.500000             85.500000   \n",
       "              2025-06-03 12:01:27.781         85.000000             85.000000   \n",
       "              2025-06-03 12:01:28.781         84.800003             84.800003   \n",
       "...                                                 ...                   ...   \n",
       "1f683         2025-06-23 19:10:25.060         16.309999             16.309999   \n",
       "              2025-06-23 19:10:26.060         16.379999             16.379999   \n",
       "              2025-06-23 19:10:27.060         16.370001             16.370001   \n",
       "              2025-06-23 19:10:28.060         16.459999             16.459999   \n",
       "              2025-06-23 19:10:29.060         17.719999             17.719999   \n",
       "\n",
       "                                       alpha__min__w=1s  ...  \\\n",
       "participantId time                                       ...   \n",
       "10d83         2025-06-03 12:01:24.781         83.599998  ...   \n",
       "              2025-06-03 12:01:25.781         83.800003  ...   \n",
       "              2025-06-03 12:01:26.781         84.699997  ...   \n",
       "              2025-06-03 12:01:27.781         84.500000  ...   \n",
       "              2025-06-03 12:01:28.781         84.500000  ...   \n",
       "...                                                 ...  ...   \n",
       "1f683         2025-06-23 19:10:25.060         16.160000  ...   \n",
       "              2025-06-23 19:10:26.060         15.850000  ...   \n",
       "              2025-06-23 19:10:27.060         16.170000  ...   \n",
       "              2025-06-23 19:10:28.060         15.940000  ...   \n",
       "              2025-06-23 19:10:29.060         11.410000  ...   \n",
       "\n",
       "                                       gamma__median__w=1s  gamma__mean__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781                7.100           7.093333   \n",
       "              2025-06-03 12:01:25.781                7.000           6.733334   \n",
       "              2025-06-03 12:01:26.781                6.450           6.340001   \n",
       "              2025-06-03 12:01:27.781                7.100           7.078261   \n",
       "              2025-06-03 12:01:28.781                7.100           7.133334   \n",
       "...                                                    ...                ...   \n",
       "1f683         2025-06-23 19:10:25.060               -3.940          -3.894166   \n",
       "              2025-06-23 19:10:26.060               -3.655          -3.572834   \n",
       "              2025-06-23 19:10:27.060               -3.830          -3.801833   \n",
       "              2025-06-23 19:10:28.060               -3.765          -4.044000   \n",
       "              2025-06-23 19:10:29.060              -15.145         -13.838166   \n",
       "\n",
       "                                       gamma__length__w=1s  \\\n",
       "participantId time                                           \n",
       "10d83         2025-06-03 12:01:24.781                   30   \n",
       "              2025-06-03 12:01:25.781                   36   \n",
       "              2025-06-03 12:01:26.781                   30   \n",
       "              2025-06-03 12:01:27.781                   23   \n",
       "              2025-06-03 12:01:28.781                   21   \n",
       "...                                                    ...   \n",
       "1f683         2025-06-23 19:10:25.060                   60   \n",
       "              2025-06-23 19:10:26.060                   60   \n",
       "              2025-06-23 19:10:27.060                   60   \n",
       "              2025-06-23 19:10:28.060                   60   \n",
       "              2025-06-23 19:10:29.060                   60   \n",
       "\n",
       "                                       gamma__std_dev__w=1s  gamma__var__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781              0.169181          0.028622   \n",
       "              2025-06-03 12:01:25.781              0.568135          0.322778   \n",
       "              2025-06-03 12:01:26.781              0.416013          0.173067   \n",
       "              2025-06-03 12:01:27.781              0.131733          0.017353   \n",
       "              2025-06-03 12:01:28.781              0.083571          0.006984   \n",
       "...                                                     ...               ...   \n",
       "1f683         2025-06-23 19:10:25.060              0.176279          0.031074   \n",
       "              2025-06-23 19:10:26.060              0.170138          0.028947   \n",
       "              2025-06-23 19:10:27.060              0.099155          0.009832   \n",
       "              2025-06-23 19:10:28.060              0.432201          0.186797   \n",
       "              2025-06-23 19:10:29.060              5.448740         29.688772   \n",
       "\n",
       "                                       gamma__root_mean_square__w=1s  \\\n",
       "participantId time                                                     \n",
       "10d83         2025-06-03 12:01:24.781                       7.095351   \n",
       "              2025-06-03 12:01:25.781                       6.757259   \n",
       "              2025-06-03 12:01:26.781                       6.353634   \n",
       "              2025-06-03 12:01:27.781                       7.079486   \n",
       "              2025-06-03 12:01:28.781                       7.133823   \n",
       "...                                                              ...   \n",
       "1f683         2025-06-23 19:10:25.060                       3.898154   \n",
       "              2025-06-23 19:10:26.060                       3.576882   \n",
       "              2025-06-23 19:10:27.060                       3.803126   \n",
       "              2025-06-23 19:10:28.060                       4.067030   \n",
       "              2025-06-23 19:10:29.060                      14.872244   \n",
       "\n",
       "                                       gamma__max__w=1s  gamma__abs_max__w=1s  \\\n",
       "participantId time                                                              \n",
       "10d83         2025-06-03 12:01:24.781              7.40                  7.40   \n",
       "              2025-06-03 12:01:25.781              7.30                  7.30   \n",
       "              2025-06-03 12:01:26.781              6.90                  6.90   \n",
       "              2025-06-03 12:01:27.781              7.30                  7.30   \n",
       "              2025-06-03 12:01:28.781              7.30                  7.30   \n",
       "...                                                 ...                   ...   \n",
       "1f683         2025-06-23 19:10:25.060             -3.44                  4.06   \n",
       "              2025-06-23 19:10:26.060             -3.25                  3.76   \n",
       "              2025-06-23 19:10:27.060             -3.58                  3.93   \n",
       "              2025-06-23 19:10:28.060             -3.69                  4.97   \n",
       "              2025-06-23 19:10:29.060             -5.06                 20.18   \n",
       "\n",
       "                                       gamma__min__w=1s  activity  \n",
       "participantId time                                                 \n",
       "10d83         2025-06-03 12:01:24.781              6.70   sitting  \n",
       "              2025-06-03 12:01:25.781              5.50   sitting  \n",
       "              2025-06-03 12:01:26.781              5.40   sitting  \n",
       "              2025-06-03 12:01:27.781              6.80   sitting  \n",
       "              2025-06-03 12:01:28.781              7.00   sitting  \n",
       "...                                                 ...       ...  \n",
       "1f683         2025-06-23 19:10:25.060             -4.06   sitting  \n",
       "              2025-06-23 19:10:26.060             -3.76   sitting  \n",
       "              2025-06-23 19:10:27.060             -3.93   sitting  \n",
       "              2025-06-23 19:10:28.060             -4.97   sitting  \n",
       "              2025-06-23 19:10:29.060            -20.18   sitting  \n",
       "\n",
       "[945 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d6fcd8a-dea4-4448-9e41-d020c166f01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "for train_idx, test_idx in splitter.split(y=df1.activity, X=df1.drop(columns=[\"activity\"]), groups=df1.reset_index().participantId):\n",
    "    train, test = df1.iloc[train_idx], df1.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1beaef1-396c-4bd0-9f58-b57f181a3046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10d83', '11416'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.reset_index().participantId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65999773-3c23-464c-a21b-aaea89ee1da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12358', '12f77', '150c9', '152a7', '15b85', '18582', '191d4',\n",
       "       '19ee7', '1a045', '1b682', '1b728', '1b949', '1dd54', '1e570',\n",
       "       '1f683'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index().participantId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab8e1b1b-4464-4b87-9e1d-c2c4a42dd43c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.12/site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (2.2.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "418dda31-9cb8-4674-8d5e-39588e200b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " Index(['walking', 'sitting', 'standing'], dtype='object'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.activity.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18560d43-3113-4f5d-98db-da6d937084a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6814/3960902939.py:16: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  study= optuna.study.create_study(sampler= optuna.samplers.GPSampler(), direction=\"maximize\")\n",
      "[I 2025-07-12 21:32:57,942] A new study created in memory with name: no-name-e430dd37-d7fc-4a67-b737-50ced9049c17\n",
      "[I 2025-07-12 21:32:58,311] Trial 0 finished with value: 0.5820993589778228 and parameters: {'max_depth': 16}. Best is trial 0 with value: 0.5820993589778228.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import optuna\n",
    "\n",
    "X,y,groups= train.drop(columns=[\"activity\"]), train.activity, train.reset_index().participantId\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    clf=Pipeline([ (\"sample\", SMOTE()) , (\"clf\",DecisionTreeClassifier(max_depth=trial.suggest_int('max_depth',1,20))),])\n",
    "    return cross_val_score(clf,X,y,cv=cv, groups=groups, scoring=\"f1_macro\").mean()\n",
    "\n",
    "study= optuna.study.create_study(sampler= optuna.samplers.GPSampler(), direction=\"maximize\")\n",
    "study.optimize(objective,n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "497cc638-d465-4e19-952a-e2c2d9fbe273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
       "        173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
       "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
       "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
       "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
       "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
       "        251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
       "        264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
       "        277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
       "        290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
       "        303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
       "        316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
       "        329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
       "        342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
       "        355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
       "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
       "        381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
       "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
       "        433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
       "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
       "        459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
       "        472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
       "        485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
       "        498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
       "        511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523,\n",
       "        524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536,\n",
       "        537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549,\n",
       "        550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562,\n",
       "        563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575,\n",
       "        576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588,\n",
       "        589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
       "        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614,\n",
       "        615, 616, 617, 618, 619, 620, 621, 622, 623]),\n",
       " array([ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "         54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "         67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "        132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "        145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "        158, 159, 160, 161]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = GroupKFold(n_splits=5)\n",
    "splits=list(cv.split(X, y, groups))\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd71dfa2-48ce-495b-a56a-c84fcd801429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6814/2964493964.py:116: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  study= optuna.study.create_study(sampler= optuna.samplers.GPSampler(), direction=\"maximize\")\n",
      "[I 2025-07-12 22:27:21,231] A new study created in memory with name: no-name-d68a36e0-f80b-442b-9dc4-b3e05f0735eb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febd8e063e5848a2a4dd03c9aff139e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-12 22:27:21,536] Trial 0 finished with value: 0.3520647083865474 and parameters: {'classifier': 'pac', 'pac_C': 0.00554046947295823}. Best is trial 0 with value: 0.3520647083865474.\n",
      "[I 2025-07-12 22:27:21,723] Trial 7 finished with value: 0.3414428646656135 and parameters: {'classifier': 'pac', 'pac_C': 0.5979225237410112}. Best is trial 0 with value: 0.3520647083865474.\n",
      "[I 2025-07-12 22:27:21,727] Trial 2 finished with value: 0.3177447981571693 and parameters: {'classifier': 'perc', 'perc_alpha': 0.06892628344471788}. Best is trial 0 with value: 0.3520647083865474.\n",
      "[I 2025-07-12 22:27:21,740] Trial 6 finished with value: 0.40221323685890614 and parameters: {'classifier': 'et', 'et_max_depth': 5, 'et_min_samples_split': 6}. Best is trial 6 with value: 0.40221323685890614.\n",
      "[I 2025-07-12 22:27:21,749] Trial 3 finished with value: 0.32511522016769395 and parameters: {'classifier': 'svc', 'svc_C': 46.778759493056604, 'svc_kernel': 'rbf', 'svc_gamma': 'auto'}. Best is trial 6 with value: 0.40221323685890614.\n",
      "[I 2025-07-12 22:27:21,824] Trial 14 finished with value: 0.47350771294433264 and parameters: {'classifier': 'lsvc', 'lsvc_C': 0.01897179501967925}. Best is trial 14 with value: 0.47350771294433264.\n",
      "[I 2025-07-12 22:27:21,842] Trial 19 finished with value: 0.4569312169312169 and parameters: {'classifier': 'ridge', 'ridge_alpha': 0.2535468746952221}. Best is trial 14 with value: 0.47350771294433264.\n",
      "[I 2025-07-12 22:27:21,920] Trial 1 finished with value: 0.685946085584422 and parameters: {'classifier': 'lsvc', 'lsvc_C': 0.179000639147837}. Best is trial 1 with value: 0.685946085584422.\n",
      "[I 2025-07-12 22:27:21,922] Trial 16 finished with value: 0.44438916528468764 and parameters: {'classifier': 'svc', 'svc_C': 0.05744185057978774, 'svc_kernel': 'rbf', 'svc_gamma': 'auto'}. Best is trial 1 with value: 0.685946085584422.\n",
      "[I 2025-07-12 22:27:21,924] Trial 10 finished with value: 0.2886497688506297 and parameters: {'classifier': 'lr', 'lr_C': 8.039711931544238}. Best is trial 1 with value: 0.685946085584422.\n",
      "[I 2025-07-12 22:27:21,933] Trial 9 finished with value: 0.17289301089249084 and parameters: {'classifier': 'perc', 'perc_alpha': 0.0018910423227513496}. Best is trial 1 with value: 0.685946085584422.\n",
      "[I 2025-07-12 22:27:21,933] Trial 5 finished with value: 0.7420112781954886 and parameters: {'classifier': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 1.0533119646709262e-05}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,025] Trial 4 finished with value: 0.13346104725415073 and parameters: {'classifier': 'svc', 'svc_C': 49.20320457285003, 'svc_kernel': 'rbf', 'svc_gamma': 'scale'}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,029] Trial 13 finished with value: 0.48502758077226166 and parameters: {'classifier': 'lr', 'lr_C': 0.46161592057767864}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,132] Trial 12 finished with value: 0.32053692771756 and parameters: {'classifier': 'ridge', 'ridge_alpha': 0.5418362496190698}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,225] Trial 20 finished with value: 0.7088030842923069 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.03934484934968979}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,250] Trial 26 finished with value: 0.6761408793816545 and parameters: {'classifier': 'pac', 'pac_C': 0.010255977214875922}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,252] Trial 24 finished with value: 0.4569312169312169 and parameters: {'classifier': 'ridge', 'ridge_alpha': 0.017044142427952217}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,322] Trial 23 finished with value: 0.24958594477585647 and parameters: {'classifier': 'svc', 'svc_C': 0.023630082865215653, 'svc_kernel': 'rbf', 'svc_gamma': 'auto'}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,323] Trial 31 finished with value: 0.3117283950617284 and parameters: {'classifier': 'dt', 'dt_max_depth': 16, 'dt_min_samples_split': 4}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,325] Trial 11 finished with value: 0.2665130568356375 and parameters: {'classifier': 'svc', 'svc_C': 0.0014716236728479568, 'svc_kernel': 'linear', 'svc_gamma': 'scale'}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,341] Trial 27 finished with value: 0.5403614457831325 and parameters: {'classifier': 'lr', 'lr_C': 0.0024762656998535736}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,349] Trial 30 finished with value: 0.283541846419327 and parameters: {'classifier': 'lr', 'lr_C': 0.7387463289000017}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,423] Trial 21 finished with value: 0.48035714285714287 and parameters: {'classifier': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 3.295698630745778e-05}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,429] Trial 17 finished with value: 0.22354522757826004 and parameters: {'classifier': 'svc', 'svc_C': 0.01832142533985176, 'svc_kernel': 'rbf', 'svc_gamma': 'auto'}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,724] Trial 22 finished with value: 0.3361253448955459 and parameters: {'classifier': 'ridge', 'ridge_alpha': 0.019150350810716293}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,751] Trial 37 finished with value: 0.43512472794240753 and parameters: {'classifier': 'perc', 'perc_alpha': 1.8445537340514183e-05}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,752] Trial 18 finished with value: 0.3177447981571693 and parameters: {'classifier': 'perc', 'perc_alpha': 1.1538418390671325e-05}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,822] Trial 28 finished with value: 0.4869715136554211 and parameters: {'classifier': 'lsvc', 'lsvc_C': 0.018577048639188284}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,846] Trial 34 finished with value: 0.3177447981571693 and parameters: {'classifier': 'perc', 'perc_alpha': 0.0025719536671223787}. Best is trial 5 with value: 0.7420112781954886.\n",
      "[I 2025-07-12 22:27:22,929] Trial 36 finished with value: 0.7983268983268982 and parameters: {'classifier': 'pac', 'pac_C': 0.0752788577138177}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:22,942] Trial 32 finished with value: 0.685946085584422 and parameters: {'classifier': 'lr', 'lr_C': 5.4449649408703085}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:23,026] Trial 33 finished with value: 0.48502758077226166 and parameters: {'classifier': 'lr', 'lr_C': 0.28556818024799874}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:23,149] Trial 38 finished with value: 0.45554150863885373 and parameters: {'classifier': 'ridge', 'ridge_alpha': 0.5987035386796354}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:23,244] Trial 40 finished with value: 0.525686259790306 and parameters: {'classifier': 'lsvc', 'lsvc_C': 15.596175883470833}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:23,346] Trial 42 finished with value: 0.3569352400883618 and parameters: {'classifier': 'ridge', 'ridge_alpha': 0.005092917953325681}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:23,725] Trial 39 finished with value: 0.3007363007363007 and parameters: {'classifier': 'svc', 'svc_C': 0.003503213091928868, 'svc_kernel': 'linear', 'svc_gamma': 'scale'}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:23,731] Trial 43 finished with value: 0.46928104575163393 and parameters: {'classifier': 'svc', 'svc_C': 0.10559907540660733, 'svc_kernel': 'rbf', 'svc_gamma': 'auto'}. Best is trial 36 with value: 0.7983268983268982.\n",
      "[I 2025-07-12 22:27:25,620] Trial 29 finished with value: 0.8665607872446438 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 138, 'etrees_max_depth': 3, 'etrees_min_samples_split': 6}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:26,034] Trial 8 finished with value: 0.012461059190031152 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 91, 'etrees_max_depth': 3, 'etrees_min_samples_split': 5}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:26,229] Trial 25 finished with value: 0.5736440169937708 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 99, 'etrees_max_depth': 19, 'etrees_min_samples_split': 9}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:27,724] Trial 15 finished with value: 0.4563966302922126 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 147, 'etrees_max_depth': 16, 'etrees_min_samples_split': 6}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:28,420] Trial 35 finished with value: 0.2657632222849614 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 117, 'etrees_max_depth': 5, 'etrees_min_samples_split': 10}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:30,432] Trial 41 finished with value: 0.7682340647857889 and parameters: {'classifier': 'rf', 'rf_n_estimators': 128, 'rf_max_depth': 3, 'rf_min_samples_split': 10}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:34,825] Trial 47 finished with value: 0.6960933536276 and parameters: {'classifier': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 0.0054009166995036785}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:35,746] Trial 48 finished with value: 0.3162426579475601 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.0003013155938774764}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:35,939] Trial 51 finished with value: 0.26652506697282813 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 2.194939710005272e-05}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:36,432] Trial 52 finished with value: 0.8539027551319035 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.0010255142415868054}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:36,854] Trial 45 finished with value: 0.2991033886460813 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 2.966884048690117e-05}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:37,525] Trial 49 finished with value: 0.7870325070667535 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.0030546206770350527}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:38,142] Trial 44 finished with value: 0.8282642089093701 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.0019702575156639725}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:38,246] Trial 53 finished with value: 0.35464624443326437 and parameters: {'classifier': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 0.029865208447184863}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:38,433] Trial 98 finished with value: 0.26489117983963345 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 56, 'etrees_max_depth': 7, 'etrees_min_samples_split': 2}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:39,034] Trial 50 finished with value: 0.27495214500728765 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.032583901475801744}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:39,633] Trial 46 finished with value: 0.7348348348348348 and parameters: {'classifier': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 0.00670157065682116}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:39,951] Trial 55 finished with value: 0.8469767948578276 and parameters: {'classifier': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.0009715949597644223}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:40,049] Trial 54 finished with value: 0.4794600938967137 and parameters: {'classifier': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 0.0009150180541358554}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:41,028] Trial 82 finished with value: 0.4854579923244093 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 57, 'etrees_max_depth': 14, 'etrees_min_samples_split': 9}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:41,044] Trial 84 finished with value: 0.5577157884850192 and parameters: {'classifier': 'rf', 'rf_n_estimators': 66, 'rf_max_depth': 17, 'rf_min_samples_split': 6}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:42,147] Trial 78 finished with value: 0.2948073701842546 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 77, 'etrees_max_depth': 3, 'etrees_min_samples_split': 6}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:43,145] Trial 85 finished with value: 0.48987833018670024 and parameters: {'classifier': 'rf', 'rf_n_estimators': 78, 'rf_max_depth': 16, 'rf_min_samples_split': 5}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:44,030] Trial 92 finished with value: 0.4998825463941743 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 68, 'etrees_max_depth': 11, 'etrees_min_samples_split': 9}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:44,926] Trial 77 finished with value: 0.32445723617961647 and parameters: {'classifier': 'rf', 'rf_n_estimators': 108, 'rf_max_depth': 2, 'rf_min_samples_split': 5}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:44,948] Trial 79 finished with value: 0.48759045107188753 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 113, 'etrees_max_depth': 19, 'etrees_min_samples_split': 8}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:45,050] Trial 75 finished with value: 0.5282186948853616 and parameters: {'classifier': 'rf', 'rf_n_estimators': 148, 'rf_max_depth': 20, 'rf_min_samples_split': 2}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:45,148] Trial 67 finished with value: 0.8665607872446438 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 85, 'etrees_max_depth': 3, 'etrees_min_samples_split': 3}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:45,328] Trial 72 finished with value: 0.527014652014652 and parameters: {'classifier': 'rf', 'rf_n_estimators': 126, 'rf_max_depth': 17, 'rf_min_samples_split': 3}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:45,728] Trial 70 finished with value: 0.33696831386176695 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 89, 'etrees_max_depth': 20, 'etrees_min_samples_split': 8}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:45,928] Trial 73 finished with value: 0.5375509480772639 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 75, 'etrees_max_depth': 12, 'etrees_min_samples_split': 8}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,038] Trial 74 finished with value: 0.4845496383957923 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 95, 'etrees_max_depth': 6, 'etrees_min_samples_split': 4}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,222] Trial 94 finished with value: 0.4090845562543676 and parameters: {'classifier': 'rf', 'rf_n_estimators': 52, 'rf_max_depth': 11, 'rf_min_samples_split': 7}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,441] Trial 96 finished with value: 0.6121149065609836 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 78, 'etrees_max_depth': 5, 'etrees_min_samples_split': 4}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,549] Trial 87 finished with value: 0.5440973707982694 and parameters: {'classifier': 'rf', 'rf_n_estimators': 113, 'rf_max_depth': 8, 'rf_min_samples_split': 7}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,627] Trial 64 finished with value: 0.44035314384151586 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 117, 'etrees_max_depth': 5, 'etrees_min_samples_split': 5}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,637] Trial 80 finished with value: 0.44919409442493513 and parameters: {'classifier': 'rf', 'rf_n_estimators': 86, 'rf_max_depth': 8, 'rf_min_samples_split': 7}. Best is trial 29 with value: 0.8665607872446438.\n",
      "[I 2025-07-12 22:27:46,850] Trial 86 finished with value: 0.9305149305149305 and parameters: {'classifier': 'rf', 'rf_n_estimators': 73, 'rf_max_depth': 9, 'rf_min_samples_split': 5}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:47,536] Trial 88 finished with value: 0.8417103364471785 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 117, 'etrees_max_depth': 12, 'etrees_min_samples_split': 6}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:47,652] Trial 56 finished with value: 0.7012987012987013 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 190, 'etrees_max_depth': 4, 'etrees_min_samples_split': 3}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:47,833] Trial 91 finished with value: 0.5001847745750184 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 127, 'etrees_max_depth': 14, 'etrees_min_samples_split': 5}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,026] Trial 60 finished with value: 0.5492391616422624 and parameters: {'classifier': 'rf', 'rf_n_estimators': 124, 'rf_max_depth': 8, 'rf_min_samples_split': 7}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,121] Trial 57 finished with value: 0.26894586894586897 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 168, 'etrees_max_depth': 11, 'etrees_min_samples_split': 6}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,345] Trial 76 finished with value: 0.36677775023639686 and parameters: {'classifier': 'rf', 'rf_n_estimators': 123, 'rf_max_depth': 4, 'rf_min_samples_split': 9}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,422] Trial 58 finished with value: 0.5339532262609186 and parameters: {'classifier': 'rf', 'rf_n_estimators': 138, 'rf_max_depth': 16, 'rf_min_samples_split': 6}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,533] Trial 97 finished with value: 0.2798446137755864 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 184, 'etrees_max_depth': 15, 'etrees_min_samples_split': 7}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,731] Trial 69 finished with value: 0.5728453631537332 and parameters: {'classifier': 'rf', 'rf_n_estimators': 168, 'rf_max_depth': 20, 'rf_min_samples_split': 3}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:48,926] Trial 81 finished with value: 0.54214050618545 and parameters: {'classifier': 'rf', 'rf_n_estimators': 189, 'rf_max_depth': 14, 'rf_min_samples_split': 4}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:49,133] Trial 66 finished with value: 0.8729743168670675 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 130, 'etrees_max_depth': 17, 'etrees_min_samples_split': 4}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:49,351] Trial 93 finished with value: 0.32754054948692485 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 121, 'etrees_max_depth': 5, 'etrees_min_samples_split': 3}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:49,539] Trial 83 finished with value: 0.3985825027685493 and parameters: {'classifier': 'rf', 'rf_n_estimators': 134, 'rf_max_depth': 15, 'rf_min_samples_split': 7}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:49,632] Trial 99 finished with value: 0.40160653481127295 and parameters: {'classifier': 'rf', 'rf_n_estimators': 134, 'rf_max_depth': 11, 'rf_min_samples_split': 4}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:49,647] Trial 71 finished with value: 0.8810667593276289 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 121, 'etrees_max_depth': 13, 'etrees_min_samples_split': 9}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:49,823] Trial 89 finished with value: 0.583648200238062 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 196, 'etrees_max_depth': 15, 'etrees_min_samples_split': 2}. Best is trial 86 with value: 0.9305149305149305.\n",
      "[I 2025-07-12 22:27:50,244] Trial 59 finished with value: 0.9518178298666103 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 176, 'etrees_max_depth': 19, 'etrees_min_samples_split': 10}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,332] Trial 61 finished with value: 0.31586871424269797 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 177, 'etrees_max_depth': 7, 'etrees_min_samples_split': 7}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,421] Trial 63 finished with value: 0.78354448444356 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 171, 'etrees_max_depth': 7, 'etrees_min_samples_split': 7}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,445] Trial 62 finished with value: 0.9232438722245647 and parameters: {'classifier': 'rf', 'rf_n_estimators': 143, 'rf_max_depth': 9, 'rf_min_samples_split': 10}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,543] Trial 95 finished with value: 0.40318836771339733 and parameters: {'classifier': 'rf', 'rf_n_estimators': 149, 'rf_max_depth': 10, 'rf_min_samples_split': 5}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,630] Trial 90 finished with value: 0.27027649769585255 and parameters: {'classifier': 'etrees', 'etrees_n_estimators': 187, 'etrees_max_depth': 14, 'etrees_min_samples_split': 6}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,722] Trial 65 finished with value: 0.711919191919192 and parameters: {'classifier': 'rf', 'rf_n_estimators': 188, 'rf_max_depth': 3, 'rf_min_samples_split': 5}. Best is trial 59 with value: 0.9518178298666103.\n",
      "[I 2025-07-12 22:27:50,745] Trial 68 finished with value: 0.40318836771339733 and parameters: {'classifier': 'rf', 'rf_n_estimators': 188, 'rf_max_depth': 10, 'rf_min_samples_split': 7}. Best is trial 59 with value: 0.9518178298666103.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
    ")\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.utils import all_estimators\n",
    "import timeout_decorator\n",
    "import random\n",
    "\n",
    "X,y,groups= train.drop(columns=[\"activity\"]), train.activity, train.reset_index().participantId\n",
    "cv = GroupKFold(n_splits=5)\n",
    "splits=list(cv.split(X, y, groups))\n",
    "\n",
    "\n",
    "\n",
    "#@timeout_decorator.timeout(30, timeout_exception=optuna.TrialPruned, use_signals=True)\n",
    "def cross_val_score_to(clf,X,y,cv=None, groups=None, scoring=None):\n",
    "    cross_val_score(clf,X,y,cv=cv, groups=groups, scoring=scoring)\n",
    "\n",
    "clfs={\n",
    "        \"lr\": LogisticRegression,\n",
    "        \"ridge\": RidgeClassifier,\n",
    "        \"sgd\": SGDClassifier,\n",
    "        \"lsvc\": LinearSVC,\n",
    "        \"svc\": SVC,\n",
    "        \"pac\": PassiveAggressiveClassifier,\n",
    "        \"perc\": Perceptron,\n",
    "        \"dt\": DecisionTreeClassifier,\n",
    "        \"et\": ExtraTreeClassifier,\n",
    "        \"rf\":RandomForestClassifier,\n",
    "        \"etrees\":ExtraTreesClassifier,\n",
    "     }\n",
    "\n",
    "def objective(trial):\n",
    "    from sklearn.datasets import load_iris  # replace with your data\n",
    "\n",
    "    model_name = trial.suggest_categorical(\"classifier\", clfs.keys())\n",
    "\n",
    "    if model_name == \"lr\":\n",
    "        clf = LogisticRegression(\n",
    "            C=trial.suggest_float(\"lr_C\", 1e-3, 100, log=True),\n",
    "            solver=\"liblinear\"\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        clf = RidgeClassifier(\n",
    "            alpha=trial.suggest_float(\"ridge_alpha\", 1e-3, 10, log=True)\n",
    "        )\n",
    "    elif model_name == \"sgd\":\n",
    "        clf = SGDClassifier(\n",
    "            loss=trial.suggest_categorical(\"sgd_loss\", [\"hinge\", \"log_loss\"]),\n",
    "            alpha=trial.suggest_float(\"sgd_alpha\", 1e-5, 1e-1, log=True),\n",
    "            max_iter=1000,\n",
    "            tol=1e-3\n",
    "        )\n",
    "    elif model_name == \"lsvc\":\n",
    "        clf = LinearSVC(\n",
    "            C=trial.suggest_float(\"lsvc_C\", 1e-3, 100, log=True),\n",
    "            max_iter=1000\n",
    "        )\n",
    "    elif model_name == \"svc\":\n",
    "        clf = SVC(\n",
    "            C=trial.suggest_float(\"svc_C\", 1e-3, 100, log=True),\n",
    "            kernel=trial.suggest_categorical(\"svc_kernel\", [\"linear\", \"rbf\"]),\n",
    "            gamma=trial.suggest_categorical(\"svc_gamma\", [\"scale\", \"auto\"])\n",
    "        )\n",
    "    elif model_name == \"pac\":\n",
    "        clf = PassiveAggressiveClassifier(\n",
    "            C=trial.suggest_float(\"pac_C\", 1e-3, 10, log=True)\n",
    "        )\n",
    "    elif model_name == \"perc\":\n",
    "        clf = Perceptron(\n",
    "            alpha=trial.suggest_float(\"perc_alpha\", 1e-5, 1e-1, log=True),\n",
    "            max_iter=1000\n",
    "        )\n",
    "    elif model_name == \"dt\":\n",
    "        clf = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"dt_max_depth\", 2, 20),\n",
    "            min_samples_split=trial.suggest_int(\"dt_min_samples_split\", 2, 10)\n",
    "        )\n",
    "    elif model_name == \"et\":\n",
    "        clf = ExtraTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"et_max_depth\", 2, 20),\n",
    "            min_samples_split=trial.suggest_int(\"et_min_samples_split\", 2, 10)\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int(\"rf_n_estimators\", 50, 200),\n",
    "            max_depth=trial.suggest_int(\"rf_max_depth\", 2, 20),\n",
    "            min_samples_split=trial.suggest_int(\"rf_min_samples_split\", 2, 10)\n",
    "        )\n",
    "    elif model_name == \"etrees\":\n",
    "        clf = ExtraTreesClassifier(\n",
    "            n_estimators=trial.suggest_int(\"etrees_n_estimators\", 50, 200),\n",
    "            max_depth=trial.suggest_int(\"etrees_max_depth\", 2, 20),\n",
    "            min_samples_split=trial.suggest_int(\"etrees_min_samples_split\", 2, 10)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # Pipeline with scaling (important for linear models and SVMs)\n",
    "    pipeline = make_pipeline(RobustScaler(), clf)\n",
    "    #return cross_val_score(clf,X,y,cv=cv, groups=groups, scoring=\"f1_macro\").mean()\n",
    "    train_idx, test_idx = random.choice(splits)\n",
    "    pipeline.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = pipeline.predict(X.iloc[test_idx])\n",
    "    return f1_score(y.iloc[test_idx], y_pred, average='macro')\n",
    "\n",
    "study= optuna.study.create_study(sampler= optuna.samplers.GPSampler(), direction=\"maximize\")\n",
    "study.optimize(objective,n_trials=100,n_jobs=-1, timeout=60, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a0dc633-cc58-4be5-a12f-ae444c8b0efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'etrees',\n",
       " 'etrees_n_estimators': 176,\n",
       " 'etrees_max_depth': 19,\n",
       " 'etrees_min_samples_split': 10}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9ed6826-a2a6-4d3f-a3a0-c1a4e1067d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(max_depth=19, min_samples_split=10, n_estimators=176)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ExtraTreesClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>ExtraTreesClassifier(max_depth=19, min_samples_split=10, n_estimators=176)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(max_depth=19, min_samples_split=10, n_estimators=176)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={k.removeprefix(study.best_params[\"classifier\"]+\"_\"): v for k, v in study.best_params.items()}\n",
    "params.pop(\"classifier\", None) \n",
    "clf=clfs[study.best_params['classifier']](**params)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "329e37de-5634-45e3-a556-da2b9dbd9db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f09eebe68d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "scaler=RobustScaler()\n",
    "pipeline = make_pipeline(scaler, clf)\n",
    "pipeline.fit(train.drop(columns=[\"activity\"]),train.activity)\n",
    "cm = confusion_matrix(test.activity, pipeline.predict(test.drop(columns=[\"activity\"])))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=train.activity.unique()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53215e10-5ebb-4f84-a448-02a75292cd57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "if( isinstance(clf,DecisionTreeClassifier) ): \n",
    "    tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e751a6cf-243e-475b-9173-1c4e03cb1d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: m2cgen in /opt/conda/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from m2cgen) (2.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install m2cgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d587e085-9d13-41d7-b03c-540126cfbafe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import m2cgen as m2c\n",
    "code = m2c.export_to_javascript(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e26e346-9347-4549-9474-26654430e365",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'feature_names_in_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_names_in_\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'DecisionTreeClassifier' object has no attribute 'feature_names_in_'"
     ]
    }
   ],
   "source": [
    "clf.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b780c00d-5b16-49c0-9fdb-95bec8097d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"scale\": [15712.007080078125, 333.96999526023865, 325.495840549469, 18.0, 6.090828824788332, 38.02796925837174, 326.204327583313, 343.15000677108765, 343.15000677108765, 323.9149887561798, 824.6800193786621, 13.893750429153442, 13.20384418964386, 18.0, 2.848453914746642, 8.581927417893894, 12.534270524978638, 14.057499647140503, 14.329999923706055, 16.414999783039093, 353.41001892089844, 8.176249980926514, 8.283334016799927, 18.0, 2.6658576261252165, 7.631589200813323, 7.092985272407532, 10.379999995231628, 9.549999713897705, 7.049999902024865], \"center\": [3549.9049072265625, 81.70000076293945, 89.27093124389648, 60.0, 0.7828531265258789, 0.6128600835800171, 92.0, 92.69999694824219, 92.69999694824219, 24.43000030517578, 613.6800231933594, 11.84749984741211, 11.865582942962646, 60.0, 0.3570331186056137, 0.12747357785701752, 13.591876983642578, 15.84000015258789, 16.8149995803833, 9.539999961853027, -26.27000331878662, -0.4399999976158142, -0.4425000697374344, 60.0, 0.4930809885263443, 0.2431403025984764, 4.943658113479614, -0.30000001192092896, 6.159999847412109, -3.4800000190734863], \"name\": \"RobustScaler\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "scaler_str=json.dumps(\n",
    "    {\n",
    "        \"scale\": list(scaler.scale_),\n",
    "        \"center\": list(scaler.center_),\n",
    "        \"name\": type(scaler).__name__\n",
    "    })\n",
    "print(scaler_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0e27f673-a771-4b92-ac57-9568499b1599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "js=f\"\"\"{code}\n",
    "\n",
    "const classifier =\n",
    "{{ \n",
    " inputs: {json.dumps(ts_cols)} ,\n",
    " classes: {json.dumps(list(clf.classes_))} ,\n",
    " window: {0-window_ms},\n",
    " score: score , \n",
    " scale: {scaler_str}\n",
    "}}\n",
    ";\n",
    "\n",
    "module.exports = classifier;\"\"\"\n",
    "\n",
    "with open(\"data_snapshot/model.mjs\", \"w\") as file:\n",
    "    file.write(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0dd0041f-7d08-483c-a2c1-c2a9ed170c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_ms=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d13cf6b6-21c7-46fd-b8ca-fcc36c834183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sitting', 'standing', 'walking'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348140b-f411-4c03-8675-4150fd50b0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
